---
title: "Assignment 3 Notebook"
author: "Yuxuan Mei"
output:
  html_document: default
  word_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
# Please do not change this
knitr::opts_chunk$set(echo = TRUE)
```
```{r, warning = FALSE, echo = FALSE, message=FALSE}
# Read the data and create the variables, please don't modify this!
## Load libraries
library(data.table)
library(ggplot2)
library(tidyverse)
library(pwr)
library(fixest)
library(modelsummary)
# Read the data
tweets_data <- fread('tweetment_effect.csv')
tweets_data[, c("X.1","X", "V1") := NULL]
setnames(tweets_data, 'treat.f', 'treatment_arm')
tweets_data[, In_group := NULL]
tweets_data[, high_followers := NULL]
tweets_data[, any_treatment := as.numeric(treatment_arm != 0)]
tweets_data[, racism.scores.post.1wk := NULL]
tweets_data[, racism.scores.post.2wk := NULL]
tweets_data[, treatment_arm := as.factor(treatment_arm)]
```


### Please read this code before starting. There are several ways to run regressions in R. I'd like us to use the function 'feols' with the option se = 'white'. We will discuss this in class.

```{r}
# Code that shows how different regression functions work:
this_reg_lm <- lm(racism.scores.post.2mon ~ any_treatment, 
                  data = tweets_data)

this_reg_feols <- feols(racism.scores.post.2mon ~ any_treatment, 
                        data = tweets_data)

this_reg_feols_robust <- feols(racism.scores.post.2mon ~ any_treatment, 
                               data = tweets_data, se = 'white')

# this_reg_feols_inter <- feols(racism.scores.post.2mon ~ any_treatment*anonymity, 
#                               data = tweets_data)

# 
modelsummary(list(this_reg_lm, this_reg_feols, this_reg_feols_robust))
# 
modelsummary(list(this_reg_lm, this_reg_feols, this_reg_feols_robust), 
             coef_map = c('any_treatment' = 'Treatment',
                'anonymity' = 'Anonymity',
                'any_treatment:anonymity' = 'Treatment * Anon.',
                '(Intercept)' = 'Constant'))
```
# 1.a: Of the above variables, please identify all that may be ‘good’ control variables in a regression where the outcome is 
# ‘racism.scores.post.2mon’ and the regressor is ‘any_treatment’?
# Note: By good control variables, I mean those which do not prevent a causal interpretation of the coefficient on treatment.

# Good control variables include anonymity, log.followers, and racism.scores.pre.2mon


# 1.b: Run a regression of ‘racism.scores.post.2mon’ on ‘any_treatment’. What do we learn from this regression about the effect of the treatment? Please explain in words in addition to just returning the number. 

Below is an example regression and how you should output it. In this regression, our outcome variable is 'anonymity' and our explanatory variable is 'log.followers'. This regression tells us whether there is correlation between anonymous twitter accounts and those who have a lot of followers (in our dataset).

```{r}
reg_anon_followers <- feols(anonymity ~ log.followers, data = tweets_data, se = 'white')
summary(reg_anon_followers)
```

Repeat the above exercise, but to answer question 1.b.
```{r}
reg_score_treat <- feols(racism.scores.post.2mon ~ any_treatment, data=tweets_data, se='white')
summary(reg_score_treat)

# Without any treatment, the racist score after 2 month of the experiment of an account is expected to be 0.25, and the p value of the intercept is very small, which suggest that the intercept is highly statistically significant and we can reject the null hypothesis.

# The racist score after 2 month of the experiment of an account is expected to decrease by 0.08 if there's any treatment. However, there's a relatively large standard error, and the p-value of the slope is 0.23, which suggest that the coefficient is not statistically significant (the treatment effect is not statistically significant from 0), and we fail to reject the null hypothesis. 
```
# 1.c Add the variables from a) as controls into the regression from b). What happens to our estimate of the effect of the treatment and its standard error? Why does this happen in words?
# Hint: we can do this by comparing the pre-treatment outcomes between the treatment and control group. If there are significant differences, then there may be a problem with the experiment.
```{r}
reg_score_cong <- feols(racism.scores.post.2mon ~ any_treatment + anonymity + log.followers + racism.scores.pre.2mon, data=tweets_data, se='white')
summary(reg_score_cong)

# The treatment effect coefficient becomes positive 0.02 now from -0.08. While the p-value of it is still large, therefore the treatment effect is still statistically insignificant. The standard error of the treatment effect was down from 0.068 to 0.046, which means we are now predicting a more accurate treatment effect. This is happening because we added three more control variables to help predict the outcome (racist score post 2 month of experiment). The large change in treatment effect coefficient may suggest that our previous regression does not do a good job in explaining the variances, and the previous treatment effect coefficient is not reliable. 
```



# 1.d Use a regression to check for differences between the treatment and control for one of the variables identified in a). Also use the prop.test function to check whether the randomization proportion was intended. Based on these results, should we be concerned that the randomization was done improperly?
# Note: Each arm of the experiment was assigned with equal probability and there are 4 treatment arms and one control.

```{r}
# check for pre-experiment characteristic difference 
reg_tre_cont <- feols(racism.scores.pre.2mon ~ any_treatment, data = tweets_data , se='white')
summary(reg_tre_cont)

# After running a regression of pre experiment racism score on treatment, we found that the treatment effect coefficient has a p-value of 0.06, which suggest that it is not statistically significant from 0. Also, we found that the intercept has a very small p-value, which suggest that there's a statistically significant difference between the pre-experiment racism scores in the treatment and control group (control mean is higher than treatment mean by 0.23). This alone shows that our experiment randomization was done improperly. 

# check for proper randomization
prop.test(tweets_data[treatment_arm == 0, .N], tweets_data[, .N], 0.2)
prop.test(tweets_data[treatment_arm == 1, .N], tweets_data[, .N], 0.2)
prop.test(tweets_data[treatment_arm == 2, .N], tweets_data[, .N], 0.2)
prop.test(tweets_data[treatment_arm == 3, .N], tweets_data[, .N], 0.2)
prop.test(tweets_data[treatment_arm == 4, .N], tweets_data[, .N], 0.2)

## All five prop.test shows large p-values (larger than 0.05), and we fail to reject the null hypothesis that the true probability of each arm/control group is equal to 0.2.
```

# 1.e BONUS: we would like to know whether treatment arm 2 or treatment arm 3 is statistically significantly better at reducing racist behavior. Perform a t.test or regression and test for the null hypothesis that treatment arm 2 has the same effect as treatment arm 3.
```{r}
data_t23 <- tweets_data[treatment_arm == 2 | treatment_arm == 3]
data_t23[treatment_arm == 2, if_t2:= 1]
data_t23[treatment_arm == 3, if_t2:= 0]
reg_t2_t3 <- feols(racism.scores.post.2mon ~ if_t2, data = data_t23 , se='white')
summary(reg_t2_t3)

# I created another data table with only arm 2 and 3 samples, and created a dummy column called if_t2 to represent whether the treatment arm is t2 or t3. From the regression above we can see that the difference in treatment effect between arm 2 and arm 3 (slope) has a p-value of 0.11, which suggests that the difference in treatment effect between arm 2 and arm 3 is statistically insignificant.

# However, from 1d we know that the experiment's randomization was not done properly, which might pose unforeseen impact on our conclusion to this question, as experiment arm 2 and experiment arm 3 is not the only difference between those two groups.
```

# 2.a Describe the treatment in the first experiment and the unit of randomization. What share was randomized to the treatment? 
(This refers to the experiment conducted in August 2015, the first experiment described in the introduction of the paper.)
```{r}
# The treatment is Back-end Fee (BF) strategy, which only shows all the fees after consumers selected tickets and proceeded to the checkout page. 50% consumers was randomized to the treatment group.
```

# 2.b Table II displays a randomization / balance check. A randomization check is a regression where the dependent variable occurs before the experiment. It should be very unlikely that there are substantial differences in before experiment variables if the experiment was done properly. Suggest a variable not used by the authors that would be appropriate to include in a balance check.   
```{r}
# Another variable could be the type of devices (mobile, laptop, tablet, desktop) consumers used for browsing the website. Purchasing behavior and pattern may differ depending on the type of devices used. For example, people who use phone to book tickets may not have enough time to use a laptop and cross compare between different tickets and websites, thus may have a higher purchasing rate.
```

# 2.c What is the effect of the treatment on the Propensity to Purchase at least one product? Calculate the 95% confidence interval for this estimate. 

```{r}
# The treatment effect on the propensity to purchase at least one product is 14.1%, the 95% CI is 14.1% +- 1.96 * 0.09%, which is [13.92, 14.28]
```

# 2.d Suppose the authors randomized by city of the event. Name one benefit that may occur as a result of this randomization strategy and one harm.
```{r}
# benefit: clustering randomization captures the spillover effects in the experiment. For example, it could take care of the impact of people comparing prices together.
# harm: randomizing at city level may cause pre experiment characteristics of the treatment and control group to have larger differences, and this difference may be hard to eliminate or reduce to a very low value.
```


# 2.e Suppose that you are the product manager for the monetization team at Stubhub. Based on the evidence presented above, would you launch the treatment to the entire site? The answer should be 1 paragraph. It should consist of an answer (Yes, no), and two pieces of evidence relating to that recommendation. Case participation will also constitute part of this grade.

```{r}
# Yes, I would recommend to launch the treatment to the entire site. Because there are statistically significant differences between BF and UF in terms of revenue, average seat price, propensity to purchase, etc (positive effects and low standard error). A lot of these variables are related to profitbaility, and even though the 12 month customer churn may decrease, it could be compensated by the increase of revenue and amount of new customers. Another reason is that the covariate balance table shows that at an individual user level, pre experiment user characteristics are very similar, which shows the randomization was likely to be done properly, which helps validate the treatment effect.

```


# How long did this assignment take you to do (hours)? How hard was it (easy, reasonable, hard, too hard)?  
About 4.5 hours. It's reasonable.


Returned a LaTex error while kniting, so I had to use the HTML version for submission. 
error message: LaTeX Error: File `siunitx.sty' not found.





